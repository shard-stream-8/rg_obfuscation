Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:01,  1.48it/s]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:01<00:00,  1.48it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.20it/s]
wandb: Currently logged in as: jacobcd52 (training-saes) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: WARNING Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.
wandb: Tracking run with wandb version 0.21.0
wandb: Run data is saved locally in /root/rg_obfuscation/wandb/run-20250720_033853-re5hd71r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run penalty-1
wandb: â­ï¸ View project at https://wandb.ai/training-saes/multiturn_island
wandb: ðŸš€ View run at https://wandb.ai/training-saes/multiturn_island/runs/re5hd71r
Loaded custom prompt for task 'largest_island' from registry
Traceback (most recent call last):
  File "/root/rg_obfuscation/train.py", line 12, in <module>
    train_multi_turn(args.config)
  File "/root/rg_obfuscation/reinforce/trainer.py", line 557, in train_multi_turn
    episode_results = run_batched_multi_turn_episodes(
  File "/root/rg_obfuscation/reinforce/trainer.py", line 357, in run_batched_multi_turn_episodes
    outputs = model.generate(
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py", line 2625, in generate
    result = self._sample(
  File "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py", line 3651, in _sample
    next_tokens = torch.multinomial(probs, num_samples=1).squeeze(1)
KeyboardInterrupt
Traceback (most recent call last):
  File "/root/rg_obfuscation/train.py", line 12, in <module>
    train_multi_turn(args.config)
  File "/root/rg_obfuscation/reinforce/trainer.py", line 557, in train_multi_turn
    episode_results = run_batched_multi_turn_episodes(
  File "/root/rg_obfuscation/reinforce/trainer.py", line 357, in run_batched_multi_turn_episodes
    outputs = model.generate(
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py", line 2625, in generate
    result = self._sample(
  File "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py", line 3651, in _sample
    next_tokens = torch.multinomial(probs, num_samples=1).squeeze(1)
KeyboardInterrupt
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mpenalty-1[0m at: [34mhttps://wandb.ai/training-saes/multiturn_island/runs/re5hd71r[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250720_033853-re5hd71r/logs[0m
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:01,  1.60it/s]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:01<00:00,  1.58it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.34it/s]
wandb: Currently logged in as: jacobcd52 (training-saes) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: WARNING Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.
wandb: Tracking run with wandb version 0.21.0
wandb: Run data is saved locally in /root/rg_obfuscation/wandb/run-20250720_035610-flgvmnwd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run penalty-2
wandb: â­ï¸ View project at https://wandb.ai/training-saes/multiturn_island
wandb: ðŸš€ View run at https://wandb.ai/training-saes/multiturn_island/runs/flgvmnwd
Loaded custom prompt for task 'largest_island' from registry
Traceback (most recent call last):
  File "/root/rg_obfuscation/train.py", line 12, in <module>
    train_multi_turn(args.config)
  File "/root/rg_obfuscation/reinforce/trainer.py", line 690, in train_multi_turn
    logits = model(input_ids).logits
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py", line 943, in wrapper
    output = func(self, *args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/transformers/models/qwen3/modeling_qwen3.py", line 570, in forward
    outputs: BaseModelOutputWithPast = self.model(
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py", line 943, in wrapper
    output = func(self, *args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/transformers/models/qwen3/modeling_qwen3.py", line 458, in forward
    layer_outputs = decoder_layer(
  File "/usr/local/lib/python3.10/dist-packages/transformers/modeling_layers.py", line 83, in __call__
    return super().__call__(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/transformers/models/qwen3/modeling_qwen3.py", line 262, in forward
    hidden_states, self_attn_weights = self.self_attn(
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/transformers/models/qwen3/modeling_qwen3.py", line 217, in forward
    attn_output, attn_weights = attention_interface(
  File "/usr/local/lib/python3.10/dist-packages/transformers/models/qwen3/modeling_qwen3.py", line 144, in eager_attention_forward
    key_states = repeat_kv(key, module.num_key_value_groups)
  File "/usr/local/lib/python3.10/dist-packages/transformers/models/qwen3/modeling_qwen3.py", line 131, in repeat_kv
    return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)
KeyboardInterrupt
Traceback (most recent call last):
  File "/root/rg_obfuscation/train.py", line 12, in <module>
    train_multi_turn(args.config)
  File "/root/rg_obfuscation/reinforce/trainer.py", line 690, in train_multi_turn
    logits = model(input_ids).logits
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py", line 943, in wrapper
    output = func(self, *args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/transformers/models/qwen3/modeling_qwen3.py", line 570, in forward
    outputs: BaseModelOutputWithPast = self.model(
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py", line 943, in wrapper
    output = func(self, *args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/transformers/models/qwen3/modeling_qwen3.py", line 458, in forward
    layer_outputs = decoder_layer(
  File "/usr/local/lib/python3.10/dist-packages/transformers/modeling_layers.py", line 83, in __call__
    return super().__call__(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/transformers/models/qwen3/modeling_qwen3.py", line 262, in forward
    hidden_states, self_attn_weights = self.self_attn(
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/transformers/models/qwen3/modeling_qwen3.py", line 217, in forward
    attn_output, attn_weights = attention_interface(
  File "/usr/local/lib/python3.10/dist-packages/transformers/models/qwen3/modeling_qwen3.py", line 144, in eager_attention_forward
    key_states = repeat_kv(key, module.num_key_value_groups)
  File "/usr/local/lib/python3.10/dist-packages/transformers/models/qwen3/modeling_qwen3.py", line 131, in repeat_kv
    return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)
KeyboardInterrupt
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mpenalty-2[0m at: [34mhttps://wandb.ai/training-saes/multiturn_island/runs/flgvmnwd[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250720_035610-flgvmnwd/logs[0m
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:01,  1.74it/s]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:01<00:00,  1.72it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.55it/s]
wandb: Currently logged in as: jacobcd52 (training-saes) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: WARNING Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.
wandb: Tracking run with wandb version 0.21.0
wandb: Run data is saved locally in /root/rg_obfuscation/wandb/run-20250720_041608-4sj941dn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run penalty-3
wandb: â­ï¸ View project at https://wandb.ai/training-saes/multiturn_island
wandb: ðŸš€ View run at https://wandb.ai/training-saes/multiturn_island/runs/4sj941dn
Loaded custom prompt for task 'largest_island' from registry
Traceback (most recent call last):
  File "/root/rg_obfuscation/train.py", line 12, in <module>
    train_multi_turn(args.config)
  File "/root/rg_obfuscation/reinforce/trainer.py", line 709, in train_multi_turn
    accumulated_raw_judge_penalties.append(episode_data['judge_raw_penalty_value'])
NameError: name 'accumulated_raw_judge_penalties' is not defined. Did you mean: 'accumulated_judge_penalties'?
Traceback (most recent call last):
  File "/root/rg_obfuscation/train.py", line 12, in <module>
    train_multi_turn(args.config)
  File "/root/rg_obfuscation/reinforce/trainer.py", line 709, in train_multi_turn
    accumulated_raw_judge_penalties.append(episode_data['judge_raw_penalty_value'])
NameError: name 'accumulated_raw_judge_penalties' is not defined. Did you mean: 'accumulated_judge_penalties'?
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mpenalty-3[0m at: [34mhttps://wandb.ai/training-saes/multiturn_island/runs/4sj941dn[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250720_041608-4sj941dn/logs[0m
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:01,  1.44it/s]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:01<00:00,  1.45it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.14it/s]
wandb: Currently logged in as: jacobcd52 (training-saes) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: WARNING Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.
wandb: Tracking run with wandb version 0.21.0
wandb: Run data is saved locally in /root/rg_obfuscation/wandb/run-20250720_041737-obdvj0wi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run penalty-4
wandb: â­ï¸ View project at https://wandb.ai/training-saes/multiturn_island
wandb: ðŸš€ View run at https://wandb.ai/training-saes/multiturn_island/runs/obdvj0wi
Loaded custom prompt for task 'largest_island' from registry
Traceback (most recent call last):
  File "/root/rg_obfuscation/train.py", line 12, in <module>
    train_multi_turn(args.config)
  File "/root/rg_obfuscation/reinforce/trainer.py", line 709, in train_multi_turn
    accumulated_raw_judge_penalties.append(episode_data['judge_raw_penalty_value'])
NameError: name 'accumulated_raw_judge_penalties' is not defined. Did you mean: 'accumulated_judge_penalties'?
Traceback (most recent call last):
  File "/root/rg_obfuscation/train.py", line 12, in <module>
    train_multi_turn(args.config)
  File "/root/rg_obfuscation/reinforce/trainer.py", line 709, in train_multi_turn
    accumulated_raw_judge_penalties.append(episode_data['judge_raw_penalty_value'])
NameError: name 'accumulated_raw_judge_penalties' is not defined. Did you mean: 'accumulated_judge_penalties'?
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mpenalty-4[0m at: [34mhttps://wandb.ai/training-saes/multiturn_island/runs/obdvj0wi[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250720_041737-obdvj0wi/logs[0m
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:01,  1.52it/s]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:01<00:00,  1.51it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.24it/s]
wandb: Currently logged in as: jacobcd52 (training-saes) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: WARNING Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.
wandb: Tracking run with wandb version 0.21.0
wandb: Run data is saved locally in /root/rg_obfuscation/wandb/run-20250720_042146-tdf9brdi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run penalty-5
wandb: â­ï¸ View project at https://wandb.ai/training-saes/multiturn_island
wandb: ðŸš€ View run at https://wandb.ai/training-saes/multiturn_island/runs/tdf9brdi
Loaded custom prompt for task 'largest_island' from registry
Traceback (most recent call last):
  File "/root/rg_obfuscation/train.py", line 12, in <module>
    train_multi_turn(args.config)
  File "/root/rg_obfuscation/reinforce/trainer.py", line 733, in train_multi_turn
    'regex_raw_counts_cot': [episode_data['regex_raw_count_cot']],
KeyError: 'regex_raw_count_cot'
Traceback (most recent call last):
  File "/root/rg_obfuscation/train.py", line 12, in <module>
    train_multi_turn(args.config)
  File "/root/rg_obfuscation/reinforce/trainer.py", line 733, in train_multi_turn
    'regex_raw_counts_cot': [episode_data['regex_raw_count_cot']],
KeyError: 'regex_raw_count_cot'
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mpenalty-5[0m at: [34mhttps://wandb.ai/training-saes/multiturn_island/runs/tdf9brdi[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250720_042146-tdf9brdi/logs[0m
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:01,  1.52it/s]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:01<00:00,  1.51it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.24it/s]
wandb: Currently logged in as: jacobcd52 (training-saes) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: WARNING Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.
wandb: Tracking run with wandb version 0.21.0
wandb: Run data is saved locally in /root/rg_obfuscation/wandb/run-20250720_043411-jkcw1t43
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run penalty-6
wandb: â­ï¸ View project at https://wandb.ai/training-saes/multiturn_island
wandb: ðŸš€ View run at https://wandb.ai/training-saes/multiturn_island/runs/jkcw1t43
Loaded custom prompt for task 'largest_island' from registry
Traceback (most recent call last):
  File "/root/rg_obfuscation/train.py", line 12, in <module>
    train_multi_turn(args.config)
  File "/root/rg_obfuscation/reinforce/trainer.py", line 562, in train_multi_turn
    episode_results = run_batched_multi_turn_episodes(
  File "/root/rg_obfuscation/reinforce/trainer.py", line 357, in run_batched_multi_turn_episodes
    outputs = model.generate(
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py", line 2625, in generate
    result = self._sample(
  File "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py", line 3609, in _sample
    outputs = model_forward(**model_inputs, return_dict=True)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py", line 943, in wrapper
    output = func(self, *args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/transformers/models/qwen3/modeling_qwen3.py", line 570, in forward
    outputs: BaseModelOutputWithPast = self.model(
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py", line 943, in wrapper
    output = func(self, *args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/transformers/models/qwen3/modeling_qwen3.py", line 458, in forward
    layer_outputs = decoder_layer(
  File "/usr/local/lib/python3.10/dist-packages/transformers/modeling_layers.py", line 83, in __call__
    return super().__call__(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/transformers/models/qwen3/modeling_qwen3.py", line 278, in forward
    hidden_states = self.mlp(hidden_states)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/transformers/models/qwen3/modeling_qwen3.py", line 84, in forward
    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
KeyboardInterrupt
Traceback (most recent call last):
  File "/root/rg_obfuscation/train.py", line 12, in <module>
    train_multi_turn(args.config)
  File "/root/rg_obfuscation/reinforce/trainer.py", line 562, in train_multi_turn
    episode_results = run_batched_multi_turn_episodes(
  File "/root/rg_obfuscation/reinforce/trainer.py", line 357, in run_batched_multi_turn_episodes
    outputs = model.generate(
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py", line 2625, in generate
    result = self._sample(
  File "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py", line 3609, in _sample
    outputs = model_forward(**model_inputs, return_dict=True)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py", line 943, in wrapper
    output = func(self, *args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/transformers/models/qwen3/modeling_qwen3.py", line 570, in forward
    outputs: BaseModelOutputWithPast = self.model(
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py", line 943, in wrapper
    output = func(self, *args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/transformers/models/qwen3/modeling_qwen3.py", line 458, in forward
    layer_outputs = decoder_layer(
  File "/usr/local/lib/python3.10/dist-packages/transformers/modeling_layers.py", line 83, in __call__
    return super().__call__(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/transformers/models/qwen3/modeling_qwen3.py", line 278, in forward
    hidden_states = self.mlp(hidden_states)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/transformers/models/qwen3/modeling_qwen3.py", line 84, in forward
    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
KeyboardInterrupt
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mpenalty-6[0m at: [34mhttps://wandb.ai/training-saes/multiturn_island/runs/jkcw1t43[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250720_043411-jkcw1t43/logs[0m
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:01,  1.61it/s]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:01<00:00,  1.59it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.36it/s]
wandb: Currently logged in as: jacobcd52 (training-saes) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: WARNING Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.
wandb: Tracking run with wandb version 0.21.0
wandb: Run data is saved locally in /root/rg_obfuscation/wandb/run-20250720_045601-5xwfyx38
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run penalty-7
wandb: â­ï¸ View project at https://wandb.ai/training-saes/multiturn_island
wandb: ðŸš€ View run at https://wandb.ai/training-saes/multiturn_island/runs/5xwfyx38
Loaded custom prompt for task 'largest_island' from registry
Traceback (most recent call last):
  File "/root/rg_obfuscation/train.py", line 12, in <module>
    train_multi_turn(args.config)
  File "/root/rg_obfuscation/reinforce/trainer.py", line 562, in train_multi_turn
    episode_results = run_batched_multi_turn_episodes(
  File "/root/rg_obfuscation/reinforce/trainer.py", line 357, in run_batched_multi_turn_episodes
    outputs = model.generate(
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py", line 2625, in generate
    result = self._sample(
  File "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py", line 3609, in _sample
    outputs = model_forward(**model_inputs, return_dict=True)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py", line 943, in wrapper
    output = func(self, *args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/transformers/models/qwen3/modeling_qwen3.py", line 570, in forward
    outputs: BaseModelOutputWithPast = self.model(
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py", line 943, in wrapper
    output = func(self, *args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/transformers/models/qwen3/modeling_qwen3.py", line 458, in forward
    layer_outputs = decoder_layer(
  File "/usr/local/lib/python3.10/dist-packages/transformers/modeling_layers.py", line 83, in __call__
    return super().__call__(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/transformers/models/qwen3/modeling_qwen3.py", line 278, in forward
    hidden_states = self.mlp(hidden_states)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/transformers/models/qwen3/modeling_qwen3.py", line 84, in forward
    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
KeyboardInterrupt
Traceback (most recent call last):
  File "/root/rg_obfuscation/train.py", line 12, in <module>
    train_multi_turn(args.config)
  File "/root/rg_obfuscation/reinforce/trainer.py", line 562, in train_multi_turn
    episode_results = run_batched_multi_turn_episodes(
  File "/root/rg_obfuscation/reinforce/trainer.py", line 357, in run_batched_multi_turn_episodes
    outputs = model.generate(
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py", line 2625, in generate
    result = self._sample(
  File "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py", line 3609, in _sample
    outputs = model_forward(**model_inputs, return_dict=True)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py", line 943, in wrapper
    output = func(self, *args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/transformers/models/qwen3/modeling_qwen3.py", line 570, in forward
    outputs: BaseModelOutputWithPast = self.model(
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py", line 943, in wrapper
    output = func(self, *args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/transformers/models/qwen3/modeling_qwen3.py", line 458, in forward
    layer_outputs = decoder_layer(
  File "/usr/local/lib/python3.10/dist-packages/transformers/modeling_layers.py", line 83, in __call__
    return super().__call__(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/transformers/models/qwen3/modeling_qwen3.py", line 278, in forward
    hidden_states = self.mlp(hidden_states)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/transformers/models/qwen3/modeling_qwen3.py", line 84, in forward
    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
KeyboardInterrupt
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mpenalty-7[0m at: [34mhttps://wandb.ai/training-saes/multiturn_island/runs/5xwfyx38[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250720_045601-5xwfyx38/logs[0m
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:01,  1.49it/s]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:01<00:00,  1.48it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.19it/s]
wandb: Currently logged in as: jacobcd52 (training-saes) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: WARNING Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.
wandb: Tracking run with wandb version 0.21.0
wandb: Run data is saved locally in /root/rg_obfuscation/wandb/run-20250720_053531-525l388e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run penalty-8
wandb: â­ï¸ View project at https://wandb.ai/training-saes/multiturn_island
wandb: ðŸš€ View run at https://wandb.ai/training-saes/multiturn_island/runs/525l388e
Loaded custom prompt for task 'largest_island' from registry
Traceback (most recent call last):
  File "/root/rg_obfuscation/train.py", line 12, in <module>
    train_multi_turn(args.config)
  File "/root/rg_obfuscation/reinforce/trainer.py", line 562, in train_multi_turn
    episode_results = run_batched_multi_turn_episodes(
  File "/root/rg_obfuscation/reinforce/trainer.py", line 357, in run_batched_multi_turn_episodes
    outputs = model.generate(
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py", line 2625, in generate
    result = self._sample(
  File "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py", line 3651, in _sample
    next_tokens = torch.multinomial(probs, num_samples=1).squeeze(1)
KeyboardInterrupt
Traceback (most recent call last):
  File "/root/rg_obfuscation/train.py", line 12, in <module>
    train_multi_turn(args.config)
  File "/root/rg_obfuscation/reinforce/trainer.py", line 562, in train_multi_turn
    episode_results = run_batched_multi_turn_episodes(
  File "/root/rg_obfuscation/reinforce/trainer.py", line 357, in run_batched_multi_turn_episodes
    outputs = model.generate(
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py", line 2625, in generate
    result = self._sample(
  File "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py", line 3651, in _sample
    next_tokens = torch.multinomial(probs, num_samples=1).squeeze(1)
KeyboardInterrupt
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mpenalty-8[0m at: [34mhttps://wandb.ai/training-saes/multiturn_island/runs/525l388e[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250720_053531-525l388e/logs[0m
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:01,  1.52it/s]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:01<00:00,  1.51it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.24it/s]
wandb: Currently logged in as: jacobcd52 (training-saes) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: WARNING Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.
wandb: Tracking run with wandb version 0.21.0
wandb: Run data is saved locally in /root/rg_obfuscation/wandb/run-20250720_061459-qjo9ijbq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run penalty-9
wandb: â­ï¸ View project at https://wandb.ai/training-saes/multiturn_island
wandb: ðŸš€ View run at https://wandb.ai/training-saes/multiturn_island/runs/qjo9ijbq
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                 avg_turn_count â–ˆâ–…â–†â–…â–†â–‚â–…â–ˆâ–‚â–ƒâ–‚â–„â–ƒâ–â–…â–ƒâ–ƒâ–„â–‚â–‚â–ƒâ–â–…â–ƒâ–…â–â–‚â–‚â–…â–…â–‚â–„â–ˆâ–‡â–‡â–‡â–†â–…â–…â–„
wandb:                completion_rate â–†â–†â–ˆâ–†â–ˆâ–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–ˆâ–†â–ˆâ–ˆâ–ƒâ–†â–ˆâ–â–ƒâ–ˆâ–ˆâ–ˆâ–ˆâ–†
wandb:             judge_penalty_mean â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         judge_penalty_mean_cot â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                judge_score_cot â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:             judge_score_output â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                           loss â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–‡â–‡â–†â–‡â–†â–†â–†â–‡â–…â–…â–„â–†â–†â–‡â–…â–†â–…â–†â–ƒâ–„â–…â–ƒâ–ƒâ–„â–ƒâ–‚â–â–„â–„
wandb:                      max_turns â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:             regex_penalty_mean â–‡â–†â–ˆâ–†â–‡â–†â–†â–…â–‚â–ƒâ–â–‚â–â–â–‚â–â–â–‚â–‚â–‚â–‚â–â–â–‚â–‚â–‚â–â–‚â–â–‚â–â–â–â–â–â–â–â–â–â–‚
wandb:         regex_penalty_mean_cot â–ˆâ–‡â–ˆâ–‡â–‡â–‚â–…â–‚â–„â–‚â–ƒâ–‚â–„â–‡â–„â–‚â–‚â–‚â–†â–…â–ƒâ–â–‡â–â–ƒâ–‚â–†â–‚â–‚â–„â–ƒâ–‚â–‚â–„â–ƒâ–â–â–„â–‚â–…
wandb:               task_reward_mean â–ƒâ–…â–…â–„â–„â–…â–†â–‚â–†â–†â–†â–‡â–†â–†â–…â–„â–…â–ˆâ–‡â–‡â–‡â–‡â–†â–ˆâ–‡â–…â–…â–‡â–…â–…â–ƒâ–…â–†â–ƒâ–â–…â–ƒâ–†â–…â–‡
wandb: task_reward_mean_regex_nonzero â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆ â–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ â–ˆ â–ˆâ–ˆ
wandb:    task_reward_mean_regex_zero â–‚â–ƒâ–â–„â–ƒâ–„â–„â–…â–‡â–ˆâ–‡â–‡â–‡â–†â–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–†â–ˆâ–‡â–‡â–†â–†â–‡â–‡â–‡â–…â–†â–‡â–†â–‡â–‡â–†â–‡â–‡â–†â–ˆ
wandb:              total_reward_mean â–â–‚â–‚â–ƒâ–ƒâ–†â–…â–ƒâ–„â–†â–‡â–‡â–†â–†â–†â–ˆâ–‡â–†â–‡â–†â–‡â–‡â–‡â–ˆâ–‡â–†â–…â–‡â–‡â–†â–…â–†â–…â–…â–…â–†â–„â–…â–…â–†
wandb:                 word_count_cot â–ƒâ–†â–†â–†â–‡â–„â–‡â–‡â–‚â–ˆâ–…â–‚â–ƒâ–‚â–„â–‚â–„â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–â–„â–…â–‚â–‚â–…â–‚â–‚â–â–ƒâ–‚â–„â–‚â–â–„â–â–…
wandb:              word_count_output â–†â–ˆâ–†â–ˆâ–†â–‚â–ƒâ–â–â–‚â–â–â–â–‚â–â–â–‚â–â–‚â–â–â–â–â–‚â–‚â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–‚
wandb: 
wandb: Run summary:
wandb:                 avg_turn_count 2.28125
wandb:                completion_rate 0.96875
wandb:             judge_penalty_mean 0
wandb:         judge_penalty_mean_cot 0
wandb:                judge_score_cot 0
wandb:             judge_score_output 0
wandb:                           loss -0.3067
wandb:                      max_turns 3
wandb:             regex_penalty_mean 0.04688
wandb:         regex_penalty_mean_cot 0.09375
wandb:               task_reward_mean 0.90625
wandb:    task_reward_mean_judge_high nan
wandb:     task_reward_mean_judge_low nan
wandb: task_reward_mean_regex_nonzero 1
wandb:    task_reward_mean_regex_zero 0.89655
wandb:              total_reward_mean 0.85938
wandb:                 word_count_cot 0.21875
wandb:              word_count_output 0.09375
wandb: 
wandb: ðŸš€ View run penalty-9 at: https://wandb.ai/training-saes/multiturn_island/runs/qjo9ijbq
wandb: â­ï¸ View project at: https://wandb.ai/training-saes/multiturn_island
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250720_061459-qjo9ijbq/logs
Loaded custom prompt for task 'largest_island' from registry
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:01,  1.51it/s]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:01<00:00,  1.50it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.23it/s]
wandb: Currently logged in as: jacobcd52 (training-saes) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: WARNING Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.
wandb: Tracking run with wandb version 0.21.0
wandb: Run data is saved locally in /root/rg_obfuscation/wandb/run-20250720_071621-6kykbwms
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run penalty-10
wandb: â­ï¸ View project at https://wandb.ai/training-saes/multiturn_island
wandb: ðŸš€ View run at https://wandb.ai/training-saes/multiturn_island/runs/6kykbwms
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                 avg_turn_count â–‡â–…â–ˆâ–†â–ƒâ–â–„â–ƒâ–‚â–„â–‚â–ƒâ–ƒâ–â–‚â–‚â–„â–‚â–‚â–…â–‚â–ƒâ–ƒâ–‚â–‚â–ƒâ–ƒâ–‚â–…â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–„â–‚â–„
wandb:                completion_rate â–ˆâ–ˆâ–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–…â–â–ˆâ–…â–ˆâ–…â–ˆâ–ˆâ–ˆâ–…â–ˆâ–…â–ˆâ–ˆâ–…â–ˆâ–…â–…â–…â–…â–â–ˆâ–ˆâ–…â–
wandb:             judge_penalty_mean â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         judge_penalty_mean_cot â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                judge_score_cot â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:             judge_score_output â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                           loss â–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–†â–†â–…â–…â–†â–†â–…â–„â–…â–ƒâ–ƒâ–†â–…â–…â–ˆâ–„â–…â–…â–†â–„â–â–„â–ƒâ–†â–…â–…â–†â–…â–„â–…â–†â–‚
wandb:                      max_turns â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:             regex_penalty_mean â–…â–†â–†â–‡â–†â–‡â–ˆâ–…â–‡â–‡â–…â–…â–…â–„â–ƒâ–ƒâ–‚â–‚â–â–ƒâ–â–â–‚â–‚â–â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–ƒ
wandb:         regex_penalty_mean_cot â–‚â–â–â–‚â–ƒâ–…â–„â–‚â–‚â–„â–ƒâ–‚â–„â–„â–…â–„â–…â–…â–…â–…â–„â–ƒâ–…â–ƒâ–†â–…â–‡â–†â–‡â–‡â–ˆâ–‡â–†â–‡â–ˆâ–†â–†â–„â–…â–†
wandb:               task_reward_mean â–…â–â–â–„â–…â–…â–„â–ƒâ–„â–†â–…â–†â–‡â–†â–…â–‡â–…â–†â–†â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb: task_reward_mean_regex_nonzero â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆ â–ˆ â–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–…â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–†â–â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:    task_reward_mean_regex_zero â–ƒâ–â–ƒâ–ƒâ–…â–…â–ƒâ–…â–ƒâ–†â–†â–†â–†â–‡â–†â–‡â–ˆâ–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡
wandb:              total_reward_mean â–‚â–ƒâ–â–â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–„â–ƒâ–…â–…â–‡â–‡â–‡â–†â–†â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡
wandb:                 word_count_cot â–‚â–â–‚â–‚â–„â–ƒâ–„â–‚â–„â–‚â–ƒâ–„â–ƒâ–…â–„â–…â–„â–‡â–„â–ƒâ–ƒâ–‡â–…â–†â–†â–‡â–ˆâ–…â–ˆâ–‡â–ˆâ–†â–‡â–…â–†â–…â–†â–…â–…â–†
wandb:              word_count_output â–…â–†â–†â–†â–ˆâ–‡â–ˆâ–„â–…â–„â–„â–‚â–â–â–â–â–â–â–‚â–ƒâ–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–â–‚â–‚â–â–‚
wandb: 
wandb: Run summary:
wandb:                 avg_turn_count 2.3125
wandb:                completion_rate 0.9375
wandb:             judge_penalty_mean 0
wandb:         judge_penalty_mean_cot 0
wandb:                judge_score_cot 0
wandb:             judge_score_output 0
wandb:                           loss -0.15664
wandb:                      max_turns 3
wandb:             regex_penalty_mean 0.09375
wandb:         regex_penalty_mean_cot 0.39062
wandb:               task_reward_mean 0.9375
wandb:    task_reward_mean_judge_high nan
wandb:     task_reward_mean_judge_low nan
wandb: task_reward_mean_regex_nonzero 1
wandb:    task_reward_mean_regex_zero 0.92308
wandb:              total_reward_mean 0.84375
wandb:                 word_count_cot 0.84375
wandb:              word_count_output 0.1875
wandb: 
wandb: ðŸš€ View run penalty-10 at: https://wandb.ai/training-saes/multiturn_island/runs/6kykbwms
wandb: â­ï¸ View project at: https://wandb.ai/training-saes/multiturn_island
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250720_071621-6kykbwms/logs
Loaded custom prompt for task 'largest_island' from registry
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:01,  1.51it/s]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:01<00:00,  1.50it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.23it/s]
wandb: Currently logged in as: jacobcd52 (training-saes) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: WARNING Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.
wandb: Tracking run with wandb version 0.21.0
wandb: Run data is saved locally in /root/rg_obfuscation/wandb/run-20250720_081707-asbwqzqx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run penalty-11
wandb: â­ï¸ View project at https://wandb.ai/training-saes/multiturn_island
wandb: ðŸš€ View run at https://wandb.ai/training-saes/multiturn_island/runs/asbwqzqx
