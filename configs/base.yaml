# Base configuration file - other configs inherit from this
# model
model_name: "Qwen/Qwen3-4B"

# task configuration
custom_verifier_path: "registry"
custom_prompt_path: "registry"

# terminal configuration
use_terminal: true
max_turns: 3

# training
batch_size: 16
gradient_accumulation_steps: 1
learning_rate: 1e-5
num_episodes: 10000
kl_coefficient: 0.0
min_thinking_tokens: 0
max_thinking_tokens: 128
max_new_tokens: 256
seed: 42
device: "cuda"

# wandb
wandb_project: "qwen3-reinforce-reasongym"
wandb_entity: null
# Optional Hugging Face repo to push the trained model (or LoRA adapters)
hf_repo_out: null

# judge penalty configuration
judge_penalty_enabled: true
judge_penalty_coefficient: 1.0
judge_model: "gpt-4.1-mini"
# Optional: Custom prompt template for CoT judge evaluation
# judge_cot_prompt_template: null  # Use default CoT prompt if not specified
# Optional: Disable output judge penalty while still logging CoT judge scores
# judge_output_penalty_disabled: false  # Set to true to disable output penalty but keep CoT logging

# regex penalty configuration
regex_penalty_enabled: false
regex_penalty_coefficient: 0.1
regex_penalty_max: 1.0
regex_penalty_target_words: [] 